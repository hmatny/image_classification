{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import knn_images\n",
    "from IPython.display import display as disp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(lst):\n",
    "    s = sum(lst)\n",
    "    return map(lambda x: float(x)/s, lst)\n",
    "\n",
    "\n",
    "def get_train_data(numBatches):\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    file = \"cifar-10-batches-py/data_batch_\" + str(numBatches)\n",
    "    batch_data_2 = knn_images.unpickle(file)\n",
    "    train_data = batch_data_2[b'data']\n",
    "    train_labels = batch_data_2[b'labels']\n",
    "\n",
    "    for i in range(1,numBatches):\n",
    "        file = \"cifar-10-batches-py/data_batch_\" + str(i)\n",
    "        batch_data = knn_images.unpickle(file)\n",
    "        data = batch_data[b'data']\n",
    "        labels = batch_data[b'labels']\n",
    "        \n",
    "        train_data = np.concatenate((train_data, data),0)\n",
    "        train_labels= np.concatenate((train_labels, labels),0)\n",
    "        \n",
    "    return train_data, train_labels\n",
    "\n",
    "def get_test_data():\n",
    "    file = \"cifar-10-batches-py/test_batch\"\n",
    "    test_batch = knn_images.unpickle(file)\n",
    "    test_data = test_batch[b'data']\n",
    "    test_labels = test_batch[b'labels']\n",
    "    \n",
    "    return test_data, test_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hadi/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.61960784, 0.62352941, 0.64705882, ..., 0.48627451, 0.50588235,\n",
      "       0.43137255]), array([0.92156863, 0.90588235, 0.90980392, ..., 0.69803922, 0.74901961,\n",
      "       0.78039216]), array([0.61960784, 0.61960784, 0.54509804, ..., 0.03137255, 0.01176471,\n",
      "       0.02745098]), array([0.60784314, 0.65490196, 0.69019608, ..., 0.19607843, 0.20392157,\n",
      "       0.19607843]), array([0.25490196, 0.2745098 , 0.18823529, ..., 0.53333333, 0.57254902,\n",
      "       0.45882353]), array([0.70196078, 0.54509804, 0.30196078, ..., 0.29803922, 0.30980392,\n",
      "       0.28627451]), array([0.62745098, 0.7254902 , 0.81960784, ..., 0.12156863, 0.13333333,\n",
      "       0.10980392]), array([0.3254902 , 0.32156863, 0.31764706, ..., 0.08627451, 0.09411765,\n",
      "       0.08627451]), array([0.09019608, 0.0745098 , 0.08235294, ..., 0.4627451 , 0.48235294,\n",
      "       0.4627451 ]), array([0.85098039, 0.82352941, 0.80392157, ..., 0.8       , 0.88235294,\n",
      "       0.8745098 ]), array([0.35294118, 0.35294118, 0.35686275, ..., 0.58039216, 0.57254902,\n",
      "       0.57254902]), array([1.        , 0.98823529, 0.98431373, ..., 0.56470588, 0.59215686,\n",
      "       0.61568627]), array([0.35686275, 0.32156863, 0.34117647, ..., 0.36078431, 0.29803922,\n",
      "       0.19607843]), array([0.1372549 , 0.24705882, 0.15294118, ..., 0.01176471, 0.01176471,\n",
      "       0.01568627]), array([0.78431373, 0.70980392, 0.77647059, ..., 0.32941176, 0.34117647,\n",
      "       0.36862745]), array([0.79607843, 0.65490196, 0.58431373, ..., 0.02745098, 0.05490196,\n",
      "       0.09411765]), array([0.37254902, 0.36078431, 0.34901961, ..., 0.16862745, 0.08627451,\n",
      "       0.10980392]), array([0.23529412, 0.27058824, 0.27843137, ..., 0.77647059, 0.76470588,\n",
      "       0.76862745]), array([0.8745098 , 0.8745098 , 0.88235294, ..., 0.30980392, 0.32941176,\n",
      "       0.4627451 ]), array([0.21568627, 0.2       , 0.19607843, ..., 0.60392157, 0.62745098,\n",
      "       0.58039216]), array([0.18823529, 0.25490196, 0.32941176, ..., 0.43921569, 0.45098039,\n",
      "       0.49411765]), array([0.96862745, 0.95294118, 0.95294118, ..., 0.9372549 , 0.92941176,\n",
      "       0.94901961]), array([0.1372549 , 0.14509804, 0.15294118, ..., 0.27058824, 0.2627451 ,\n",
      "       0.25490196]), array([0.30980392, 0.30588235, 0.31372549, ..., 0.51764706, 0.49803922,\n",
      "       0.48235294]), array([0.53333333, 0.55686275, 0.58431373, ..., 0.29803922, 0.29803922,\n",
      "       0.33333333]), array([0.39215686, 0.26666667, 0.45490196, ..., 0.26666667, 0.36862745,\n",
      "       0.39215686]), array([0.41960784, 0.48627451, 0.49803922, ..., 0.94117647, 0.74117647,\n",
      "       0.42745098]), array([0.82745098, 0.8627451 , 0.8745098 , ..., 0.1254902 , 0.09411765,\n",
      "       0.0745098 ]), array([0.4745098 , 0.58431373, 0.56862745, ..., 0.81568627, 0.80784314,\n",
      "       0.79215686]), array([0.34509804, 0.3254902 , 0.39607843, ..., 0.05490196, 0.0745098 ,\n",
      "       0.07058824]), array([0.22352941, 0.30588235, 0.38039216, ..., 0.28235294, 0.23921569,\n",
      "       0.27058824]), array([0.49803922, 0.50980392, 0.52941176, ..., 0.23921569, 0.21176471,\n",
      "       0.24705882]), array([0.4       , 0.47843137, 0.34901961, ..., 0.5254902 , 0.54509804,\n",
      "       0.56078431]), array([0.4627451 , 0.47843137, 0.45490196, ..., 0.80392157, 0.79215686,\n",
      "       0.78431373]), array([0.53333333, 0.54901961, 0.55686275, ..., 0.24705882, 0.23529412,\n",
      "       0.21960784]), array([0.25882353, 0.25882353, 0.25098039, ..., 0.57254902, 0.56862745,\n",
      "       0.56470588]), array([0.64705882, 0.63137255, 0.58823529, ..., 0.38039216, 0.3254902 ,\n",
      "       0.36078431]), array([1., 1., 1., ..., 1., 1., 1.]), array([0.85882353, 0.85490196, 0.83529412, ..., 0.44313725, 0.51372549,\n",
      "       0.59215686]), array([0.28235294, 0.21568627, 0.23921569, ..., 0.38039216, 0.36470588,\n",
      "       0.39607843]), array([0.18039216, 0.18039216, 0.18431373, ..., 0.34901961, 0.29803922,\n",
      "       0.31764706]), array([0.18823529, 0.17647059, 0.09411765, ..., 0.10196078, 0.05882353,\n",
      "       0.08627451]), array([0.58431373, 0.58431373, 0.54901961, ..., 0.19607843, 0.07058824,\n",
      "       0.07843137]), array([0.2745098 , 0.26666667, 0.17647059, ..., 0.32941176, 0.40784314,\n",
      "       0.41568627]), array([0.18431373, 0.18039216, 0.17647059, ..., 0.25882353, 0.25098039,\n",
      "       0.25490196]), array([0.67058824, 0.66666667, 0.65882353, ..., 0.68627451, 0.69411765,\n",
      "       0.69803922]), array([0.08627451, 0.11764706, 0.11764706, ..., 0.30980392, 0.27843137,\n",
      "       0.28235294]), array([0.28235294, 0.28235294, 0.28627451, ..., 0.11372549, 0.1372549 ,\n",
      "       0.15686275]), array([0.45490196, 0.34509804, 0.35686275, ..., 0.39607843, 0.40392157,\n",
      "       0.36862745]), array([0.41176471, 0.40392157, 0.41176471, ..., 0.25490196, 0.30588235,\n",
      "       0.25098039]), array([0.58823529, 0.57647059, 0.57647059, ..., 0.2       , 0.19607843,\n",
      "       0.15294118]), array([0.38039216, 0.36862745, 0.38039216, ..., 0.13333333, 0.1254902 ,\n",
      "       0.10196078]), array([0.3254902 , 0.25490196, 0.29411765, ..., 0.19607843, 0.20392157,\n",
      "       0.17647059]), array([1.        , 0.97647059, 0.89803922, ..., 0.        , 0.        ,\n",
      "       0.01176471]), array([0.90196078, 0.90980392, 0.92156863, ..., 0.15686275, 0.15294118,\n",
      "       0.14901961]), array([0.61960784, 0.61568627, 0.61568627, ..., 0.32156863, 0.3372549 ,\n",
      "       0.35686275]), array([0.29803922, 0.24705882, 0.15294118, ..., 0.30196078, 0.29803922,\n",
      "       0.29019608]), array([0.        , 0.        , 0.        , ..., 0.2745098 , 0.36470588,\n",
      "       0.39607843]), array([0.52941176, 0.5372549 , 0.56078431, ..., 0.6       , 0.60392157,\n",
      "       0.63137255]), array([0.50196078, 0.59215686, 0.60784314, ..., 0.50196078, 0.48235294,\n",
      "       0.43529412]), array([0.41176471, 0.4       , 0.40784314, ..., 0.49803922, 0.48627451,\n",
      "       0.5254902 ]), array([0.03921569, 0.03921569, 0.03921569, ..., 0.2627451 , 0.28235294,\n",
      "       0.32156863]), array([0.        , 0.        , 0.01176471, ..., 0.03921569, 0.20784314,\n",
      "       0.34509804]), array([0.91372549, 0.78823529, 0.85098039, ..., 0.45882353, 0.47058824,\n",
      "       0.41960784]), array([0.50588235, 0.5372549 , 0.55294118, ..., 0.49019608, 0.49019608,\n",
      "       0.43137255]), array([0.78823529, 0.73333333, 0.57254902, ..., 0.10980392, 0.08235294,\n",
      "       0.04313725]), array([0.42745098, 0.32941176, 0.39215686, ..., 0.45490196, 0.45882353,\n",
      "       0.47058824]), array([0.29803922, 0.30196078, 0.31372549, ..., 0.92941176, 0.93333333,\n",
      "       0.9372549 ]), array([0.23921569, 0.21568627, 0.22745098, ..., 0.12156863, 0.18823529,\n",
      "       0.20784314]), array([1.        , 0.85882353, 0.90588235, ..., 0.12156863, 0.10980392,\n",
      "       0.11764706]), array([0.75686275, 0.70980392, 0.73333333, ..., 0.64313725, 0.6627451 ,\n",
      "       0.67058824]), array([0.05490196, 0.05882353, 0.06666667, ..., 0.28235294, 0.27058824,\n",
      "       0.25098039]), array([0.84313725, 0.82745098, 0.81176471, ..., 0.51764706, 0.50980392,\n",
      "       0.50588235]), array([0.29803922, 0.29803922, 0.30980392, ..., 0.28627451, 0.28627451,\n",
      "       0.27843137]), array([0.90980392, 0.94117647, 0.94901961, ..., 0.30196078, 0.3254902 ,\n",
      "       0.36078431]), array([0.24705882, 0.24705882, 0.25490196, ..., 0.57254902, 0.36078431,\n",
      "       0.34117647]), array([0.63921569, 0.63137255, 0.63137255, ..., 0.51372549, 0.50980392,\n",
      "       0.51372549]), array([0.2       , 0.22352941, 0.23921569, ..., 0.1254902 , 0.10980392,\n",
      "       0.10980392]), array([0.14901961, 0.19607843, 0.14509804, ..., 0.16078431, 0.19607843,\n",
      "       0.21568627]), array([1.        , 0.98431373, 0.98431373, ..., 0.98039216, 0.98039216,\n",
      "       0.98431373]), array([0.91372549, 0.90980392, 0.91764706, ..., 0.53333333, 0.54117647,\n",
      "       0.54901961]), array([0.00784314, 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "       0.        ]), array([0.17647059, 0.19215686, 0.24313725, ..., 0.51372549, 0.51764706,\n",
      "       0.49411765]), array([0.95294118, 0.94509804, 0.95686275, ..., 0.81176471, 0.74901961,\n",
      "       0.7254902 ]), array([0.91372549, 0.88627451, 0.89411765, ..., 0.53333333, 0.54117647,\n",
      "       0.50196078]), array([0.44313725, 0.44313725, 0.45098039, ..., 0.34117647, 0.3372549 ,\n",
      "       0.32156863]), array([0.45490196, 0.43137255, 0.39607843, ..., 0.0627451 , 0.05490196,\n",
      "       0.04313725]), array([0.96470588, 0.96078431, 0.96470588, ..., 0.28235294, 0.28235294,\n",
      "       0.27058824]), array([0.95294118, 0.9372549 , 0.92941176, ..., 0.49803922, 0.52941176,\n",
      "       0.50196078]), array([0.5372549 , 0.52156863, 0.50588235, ..., 0.38039216, 0.36862745,\n",
      "       0.35294118]), array([0.45098039, 0.44705882, 0.44705882, ..., 0.54509804, 0.54901961,\n",
      "       0.55686275]), array([0.28235294, 0.2745098 , 0.24705882, ..., 0.29019608, 0.1372549 ,\n",
      "       0.09803922]), array([0.65098039, 0.67058824, 0.67843137, ..., 0.58431373, 0.55294118,\n",
      "       0.50196078]), array([0.49803922, 0.45882353, 0.44313725, ..., 0.26666667, 0.30588235,\n",
      "       0.28627451]), array([0.24705882, 0.22745098, 0.27843137, ..., 0.23921569, 0.25098039,\n",
      "       0.25882353]), array([0.20784314, 0.24313725, 0.21960784, ..., 0.35294118, 0.29803922,\n",
      "       0.3372549 ]), array([0.22352941, 0.48627451, 0.41176471, ..., 0.26666667, 0.22745098,\n",
      "       0.09019608]), array([0.51764706, 0.52156863, 0.52941176, ..., 0.56470588, 0.56078431,\n",
      "       0.56078431]), array([1., 1., 1., ..., 1., 1., 1.]), array([0.91764706, 0.93333333, 0.9372549 , ..., 0.49019608, 0.5372549 ,\n",
      "       0.49803922]), array([0.4627451 , 0.4627451 , 0.47058824, ..., 0.69803922, 0.70196078,\n",
      "       0.69803922]), array([0.23529412, 0.23529412, 0.22745098, ..., 0.80784314, 0.79607843,\n",
      "       0.81176471]), array([0.05882353, 0.05882353, 0.05882353, ..., 0.04313725, 0.04313725,\n",
      "       0.03921569]), array([1.        , 1.        , 1.        , ..., 0.04705882, 0.04705882,\n",
      "       0.09803922]), array([0.96078431, 0.96078431, 0.96470588, ..., 0.54901961, 0.52941176,\n",
      "       0.51764706]), array([1.        , 0.98823529, 0.94509804, ..., 0.99215686, 0.99215686,\n",
      "       0.99215686]), array([0.2       , 0.18823529, 0.18823529, ..., 0.42745098, 0.43137255,\n",
      "       0.43137255]), array([0.24313725, 0.15294118, 0.17647059, ..., 0.0745098 , 0.06666667,\n",
      "       0.06666667]), array([0.65098039, 0.63529412, 0.64705882, ..., 0.16862745, 0.16862745,\n",
      "       0.16470588]), array([0.04313725, 0.04705882, 0.03921569, ..., 0.0627451 , 0.0627451 ,\n",
      "       0.0627451 ]), array([0.56862745, 0.6       , 0.57647059, ..., 0.32941176, 0.25490196,\n",
      "       0.37647059]), array([0.55686275, 0.46666667, 0.43921569, ..., 0.38431373, 0.3254902 ,\n",
      "       0.3372549 ]), array([0.80784314, 0.8627451 , 0.89411765, ..., 0.36470588, 0.35686275,\n",
      "       0.37647059]), array([0.44705882, 0.45882353, 0.46666667, ..., 0.12941176, 0.14901961,\n",
      "       0.16862745]), array([0.78039216, 0.76470588, 0.75686275, ..., 0.37254902, 0.38431373,\n",
      "       0.39607843]), array([0.37254902, 0.37647059, 0.40784314, ..., 0.70980392, 0.70588235,\n",
      "       0.69019608]), array([0.40392157, 0.4       , 0.4       , ..., 0.65882353, 0.69803922,\n",
      "       0.73333333]), array([0.99607843, 0.98823529, 0.98039216, ..., 0.85098039, 0.8       ,\n",
      "       0.85098039]), array([0.01568627, 0.00784314, 0.01176471, ..., 0.00392157, 0.00392157,\n",
      "       0.00784314]), array([0.17254902, 0.18431373, 0.09411765, ..., 0.56470588, 0.55686275,\n",
      "       0.54901961]), array([0.85490196, 0.85098039, 0.85098039, ..., 0.46666667, 0.45098039,\n",
      "       0.44705882]), array([0.05098039, 0.04705882, 0.05098039, ..., 0.31764706, 0.30980392,\n",
      "       0.30196078]), array([0.2       , 0.18431373, 0.15686275, ..., 0.48627451, 0.50588235,\n",
      "       0.51764706]), array([0.80392157, 0.80392157, 0.80784314, ..., 0.21960784, 0.30196078,\n",
      "       0.31764706]), array([0.40392157, 0.39607843, 0.40392157, ..., 0.50980392, 0.50196078,\n",
      "       0.49803922]), array([0.85098039, 0.76470588, 0.76078431, ..., 0.19215686, 0.36862745,\n",
      "       0.40392157]), array([0.59607843, 0.58823529, 0.59215686, ..., 0.38823529, 0.40392157,\n",
      "       0.41176471]), array([0.27843137, 0.28627451, 0.25098039, ..., 0.01176471, 0.00392157,\n",
      "       0.00392157]), array([0.3372549 , 0.32941176, 0.32156863, ..., 0.78039216, 0.76862745,\n",
      "       0.80392157]), array([0.58431373, 0.61176471, 0.66666667, ..., 0.60392157, 0.50196078,\n",
      "       0.50980392]), array([0.21960784, 0.2627451 , 0.38823529, ..., 0.27843137, 0.33333333,\n",
      "       0.4       ]), array([0.94509804, 0.94901961, 0.95294118, ..., 0.64705882, 0.65882353,\n",
      "       0.63921569]), array([0.6627451 , 0.66666667, 0.68627451, ..., 0.51372549, 0.52156863,\n",
      "       0.50196078]), array([0.53333333, 0.56862745, 0.57647059, ..., 0.82745098, 0.82352941,\n",
      "       0.81960784]), array([0.87843137, 0.91764706, 0.9254902 , ..., 0.98431373, 0.98823529,\n",
      "       0.99215686]), array([0.66666667, 0.72941176, 0.76470588, ..., 0.25490196, 0.31372549,\n",
      "       0.36862745]), array([1.        , 0.99607843, 1.        , ..., 0.38431373, 0.51372549,\n",
      "       0.65490196]), array([0.16470588, 0.16862745, 0.18039216, ..., 0.36862745, 0.3372549 ,\n",
      "       0.31764706]), array([0.41176471, 0.45098039, 0.45098039, ..., 0.18431373, 0.16078431,\n",
      "       0.11372549]), array([0.61568627, 0.58431373, 0.56470588, ..., 0.48627451, 0.41960784,\n",
      "       0.44313725]), array([0.6745098 , 0.61568627, 0.65098039, ..., 0.49019608, 0.46666667,\n",
      "       0.46666667]), array([0.62352941, 0.63137255, 0.61568627, ..., 0.21568627, 0.21960784,\n",
      "       0.20392157]), array([1.        , 1.        , 1.        , ..., 0.99607843, 0.99607843,\n",
      "       0.99607843]), array([0.29803922, 0.39215686, 0.37254902, ..., 0.20784314, 0.13333333,\n",
      "       0.14509804]), array([0.96862745, 0.97647059, 0.98431373, ..., 0.20392157, 0.22745098,\n",
      "       0.21960784]), array([0.97254902, 0.99607843, 0.99607843, ..., 0.27843137, 0.41960784,\n",
      "       0.55294118]), array([0.21568627, 0.19215686, 0.19215686, ..., 0.1372549 , 0.14509804,\n",
      "       0.14509804]), array([0.16470588, 0.18823529, 0.20784314, ..., 0.54901961, 0.51764706,\n",
      "       0.50196078]), array([0.05490196, 0.02352941, 0.02745098, ..., 0.04705882, 0.04313725,\n",
      "       0.04705882]), array([0.40784314, 0.38431373, 0.43137255, ..., 0.15294118, 0.08235294,\n",
      "       0.1254902 ]), array([0.98823529, 0.98431373, 0.98431373, ..., 0.56078431, 0.56470588,\n",
      "       0.6627451 ]), array([1.        , 1.        , 1.        , ..., 0.18039216, 0.17647059,\n",
      "       0.17254902]), array([0.21176471, 0.19215686, 0.15686275, ..., 0.50980392, 0.50588235,\n",
      "       0.49803922]), array([0.82745098, 0.81176471, 0.82352941, ..., 0.59607843, 0.60392157,\n",
      "       0.6       ]), array([0.15686275, 0.15686275, 0.15294118, ..., 0.79607843, 0.77254902,\n",
      "       0.73333333]), array([0.06666667, 0.06666667, 0.07058824, ..., 0.56078431, 0.48235294,\n",
      "       0.41176471]), array([0.69019608, 0.68627451, 0.70196078, ..., 0.80392157, 0.81176471,\n",
      "       0.81568627]), array([1.        , 0.98431373, 0.98431373, ..., 0.48235294, 0.47058824,\n",
      "       0.4627451 ]), array([0.60784314, 0.58039216, 0.57647059, ..., 0.67058824, 0.67058824,\n",
      "       0.60784314]), array([0.48235294, 0.47843137, 0.47843137, ..., 0.65490196, 0.63529412,\n",
      "       0.61568627]), array([0.66666667, 0.67843137, 0.67058824, ..., 0.81176471, 0.81568627,\n",
      "       0.80392157]), array([0.10588235, 0.08627451, 0.09019608, ..., 0.49411765, 0.48235294,\n",
      "       0.47843137]), array([0.15686275, 0.11372549, 0.0745098 , ..., 0.69019608, 0.74509804,\n",
      "       0.74509804]), array([0.42745098, 0.35686275, 0.58039216, ..., 0.23137255, 0.33333333,\n",
      "       0.48235294]), array([0.56862745, 0.56470588, 0.57647059, ..., 0.56470588, 0.45490196,\n",
      "       0.36862745]), array([0.6745098 , 0.64313725, 0.64705882, ..., 0.34509804, 0.3254902 ,\n",
      "       0.34509804]), array([0.55686275, 0.55686275, 0.56078431, ..., 0.58823529, 0.60784314,\n",
      "       0.60784314]), array([0.42352941, 0.40784314, 0.42745098, ..., 0.26666667, 0.25490196,\n",
      "       0.27843137]), array([1.        , 1.        , 1.        , ..., 0.47058824, 0.41568627,\n",
      "       0.42745098]), array([0.71372549, 0.72941176, 0.74509804, ..., 0.20392157, 0.15294118,\n",
      "       0.11372549]), array([0.3254902 , 0.33333333, 0.34117647, ..., 0.35294118, 0.36078431,\n",
      "       0.35686275]), array([0.84313725, 0.8627451 , 0.8745098 , ..., 0.17647059, 0.15686275,\n",
      "       0.14117647]), array([0.63529412, 0.63921569, 0.56470588, ..., 0.49411765, 0.38039216,\n",
      "       0.32941176]), array([0.17647059, 0.17647059, 0.18431373, ..., 0.14901961, 0.14901961,\n",
      "       0.15294118]), array([0.3372549 , 0.31764706, 0.3254902 , ..., 0.5254902 , 0.53333333,\n",
      "       0.52156863]), array([0.87058824, 0.85490196, 0.84705882, ..., 0.83921569, 0.83137255,\n",
      "       0.82352941]), array([0.29411765, 0.2       , 0.21568627, ..., 0.78039216, 0.79607843,\n",
      "       0.8       ]), array([0.30588235, 0.37647059, 0.37254902, ..., 0.29803922, 0.31764706,\n",
      "       0.30196078]), array([0.55686275, 0.63137255, 0.6627451 , ..., 0.50980392, 0.50196078,\n",
      "       0.43529412]), array([0.76862745, 0.70196078, 0.55294118, ..., 0.61960784, 0.62352941,\n",
      "       0.63137255]), array([0.61568627, 0.83921569, 0.8627451 , ..., 0.56470588, 0.58823529,\n",
      "       0.62745098]), array([1.        , 1.        , 1.        , ..., 0.92941176, 0.96078431,\n",
      "       1.        ]), array([0.57254902, 0.51372549, 0.58431373, ..., 0.47843137, 0.4627451 ,\n",
      "       0.48235294]), array([0.47843137, 0.51372549, 0.45882353, ..., 0.5254902 , 0.55686275,\n",
      "       0.56078431]), array([0.84313725, 0.84313725, 0.86666667, ..., 0.51372549, 0.50980392,\n",
      "       0.50980392]), array([0.41176471, 0.40784314, 0.40784314, ..., 0.36078431, 0.35294118,\n",
      "       0.38431373]), array([0.11764706, 0.12941176, 0.11764706, ..., 0.06666667, 0.02745098,\n",
      "       0.01568627]), array([0.85882353, 0.8745098 , 0.82745098, ..., 0.83137255, 0.83529412,\n",
      "       0.78823529]), array([1., 1., 1., ..., 1., 1., 1.]), array([0.69411765, 0.49803922, 0.4627451 , ..., 0.5254902 , 0.58823529,\n",
      "       0.50980392]), array([0.88627451, 0.92941176, 0.93333333, ..., 0.13333333, 0.16862745,\n",
      "       0.1372549 ]), array([0.52156863, 0.54509804, 0.4627451 , ..., 0.91764706, 0.8627451 ,\n",
      "       0.82745098]), array([0.42352941, 0.44313725, 0.45882353, ..., 0.58431373, 0.49019608,\n",
      "       0.31372549]), array([0.20784314, 0.22745098, 0.11372549, ..., 0.43921569, 0.42352941,\n",
      "       0.42745098]), array([0.61568627, 0.62745098, 0.64705882, ..., 0.44705882, 0.49803922,\n",
      "       0.44705882]), array([0.1372549 , 0.10196078, 0.11372549, ..., 0.33333333, 0.33333333,\n",
      "       0.41960784]), array([0.96078431, 0.94901961, 0.96862745, ..., 0.77254902, 0.78039216,\n",
      "       0.76078431]), array([0.92941176, 0.91764706, 0.91372549, ..., 0.65098039, 0.63921569,\n",
      "       0.63529412]), array([0.89019608, 0.89803922, 0.85490196, ..., 0.78039216, 0.7254902 ,\n",
      "       0.76862745]), array([0.37254902, 0.38431373, 0.36862745, ..., 0.78431373, 0.76862745,\n",
      "       0.75686275])]\n"
     ]
    }
   ],
   "source": [
    "# retrieve train_data, train_labels\n",
    "train_data, train_labels = get_train_data(5)\n",
    "test_data, test_labels = get_test_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "train_data = train_data[:1000]\n",
    "\n",
    "test_labels = test_labels[:200]\n",
    "test_data = test_data[:200]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit on training set only.\n",
    "scaler.fit(train_data)\n",
    "# Apply transform to both the training set and the test set.\n",
    "train_data = scaler.transform(train_data)\n",
    "# test_data = scaler.transform(test_data)\n",
    "temp_data = list(range(len(test_data)))\n",
    "for i in range(len(test_data)):\n",
    "    temp_data[i] = test_data[i]/255.0\n",
    "print(temp_data)\n",
    "# from sklearn.decomposition import PCA\n",
    "# # Make an instance of the Model\n",
    "# pca = PCA(.95)\n",
    "# pca.fit(train_data)\n",
    "# train_data = pca.transform(train_data)\n",
    "# test_data = pca.transform(test_data)\n",
    "# # # normalize data\n",
    "# # norm_data = []\n",
    "# # for i in test_data:\n",
    "# #     norm_data.append(i/max(i))\n",
    "    \n",
    "# # test_data = norm_data\n",
    "\n",
    "# # norm_data = []\n",
    "# # for i in train_data:\n",
    "# #     norm_data.append(i/max(i))\n",
    "# # train_data = norm_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [200, 1000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-96cbe384436a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#retrieve knn model with specified number of k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-96cbe384436a>\u001b[0m in \u001b[0;36mfit_knn\u001b[0;34m(train_data, train_labels, k)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#fit data in classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \"\"\"\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [200, 1000]"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "def fit_knn(train_data, train_labels, k):\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(train_data,train_labels) #fit data in classifier\n",
    "    return knn\n",
    "\n",
    "#retrieve knn model with specified number of k\n",
    "knn = fit_knn(train_data, train_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.3098092079162598\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "pred_labels = knn.predict(test_data)\n",
    "print(\"time: \" + str(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20  0  0  0  0  0  0  0  0  0]\n",
      " [14  0  0  0  0  0  0  0  0  0]\n",
      " [21  0  0  0  0  0  0  0  0  0]\n",
      " [19  0  0  0  0  0  0  0  0  0]\n",
      " [15  0  0  0  0  0  0  0  0  0]\n",
      " [18  0  0  0  0  0  0  0  0  0]\n",
      " [25  0  0  0  0  1  0  0  0  0]\n",
      " [18  0  0  0  0  0  0  0  0  0]\n",
      " [28  0  0  0  0  0  0  0  0  0]\n",
      " [21  0  0  0  0  0  0  0  0  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.10      1.00      0.18        20\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.00      0.00      0.00        21\n",
      "          3       0.00      0.00      0.00        19\n",
      "          4       0.00      0.00      0.00        15\n",
      "          5       0.00      0.00      0.00        18\n",
      "          6       0.00      0.00      0.00        26\n",
      "          7       0.00      0.00      0.00        18\n",
      "          8       0.00      0.00      0.00        28\n",
      "          9       0.00      0.00      0.00        21\n",
      "\n",
      "avg / total       0.01      0.10      0.02       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hadi/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(test_labels, pred_labels))  \n",
    "print(classification_report(test_labels, pred_labels))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  0  1  0  5  0  0  0  2  3]\n",
      " [ 0  3  2  1  1  0  1  1  4  1]\n",
      " [ 2  0  4  0  8  1  4  1  1  0]\n",
      " [ 2  0  4  0  4  4  3  1  1  0]\n",
      " [ 0  0  2  1  9  0  1  0  1  1]\n",
      " [ 1  1  3  1  8  0  1  2  1  0]\n",
      " [ 2  0  5  1 10  0  8  0  0  0]\n",
      " [ 4  2  1  0  5  1  1  4  0  0]\n",
      " [ 4  1  0  2  4  1  1  0 12  3]\n",
      " [ 6  0  0  1  4  0  0  1  7  2]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.30      0.45      0.36        20\n",
      "          1       0.43      0.21      0.29        14\n",
      "          2       0.18      0.19      0.19        21\n",
      "          3       0.00      0.00      0.00        19\n",
      "          4       0.16      0.60      0.25        15\n",
      "          5       0.00      0.00      0.00        18\n",
      "          6       0.40      0.31      0.35        26\n",
      "          7       0.40      0.22      0.29        18\n",
      "          8       0.41      0.43      0.42        28\n",
      "          9       0.20      0.10      0.13        21\n",
      "\n",
      "avg / total       0.26      0.26      0.24       200\n",
      "\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## CROSS VALIDATION\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def cross_val(a,b):\n",
    "    #create new a knn model\n",
    "    knn2 = KNeighborsClassifier()\n",
    "    #create a dictionary of all values we want to test for n_neighbors \n",
    "    param_grid = {'n_neighbors': np.arange(a,b)}\n",
    "    #use gridsearch to test all values for n_neighbors\n",
    "    knn_gscv = GridSearchCV(knn2, param_grid, cv=5)\n",
    "    #fit model to data\n",
    "    knn_gscv.fit(train_data,train_labels)\n",
    "    #check top performing n_neighbors value\n",
    "    k = knn_gscv.best_params_['n_neighbors']\n",
    "    \n",
    "    knn = fit_knn(train_data, train_labels, k)\n",
    "    pred_labels = knn.predict(test_data)\n",
    "    print(confusion_matrix(test_labels, pred_labels))  \n",
    "    print(classification_report(test_labels, pred_labels))\n",
    "    conf = confusion_matrix(test_labels, pred_labels)\n",
    "    clas_rep = classification_report(test_labels, pred_labels)\n",
    "    f = open('report.txt', 'a')\n",
    "    f.write(\"\\nSTEP 4: \\n\")\n",
    "    f.write(str(conf))\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(str(clas_rep))\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.close()\n",
    "\n",
    "\n",
    "    return k\n",
    "\n",
    "k = cross_val(5,15)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes the labels to apply binary classification (1 vs 0)\n",
    "\n",
    "def binary_labels(labels, target):\n",
    "    return [1 if label == target else 0 for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm\n",
    "# from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def predict_svm(train,test):\n",
    "    train_data,train_labels = train\n",
    "    test_data,test_labels = test\n",
    "    # 10 svms to predict each class 1vsALL\n",
    "    svms = [LinearSVC(C=4) for i in range(10)]\n",
    "    # fit 10 models\n",
    "    svms = [svms[i].fit(train_data,binary_labels(train_labels,i)) for i in range(10)]\n",
    "    # should return list of lists, where predictions[5] = labels predicted for class 5 ...\n",
    "    print(\"Now predicting!\")\n",
    "    preds = [svms[i].predict(test_data) for i in range(10)]\n",
    "    return preds\n",
    "\n",
    "def svm_acc(preds, test_labels):\n",
    "    acc = 0\n",
    "    for i in range(len(test_labels)):\n",
    "        label = test_labels[i]\n",
    "        svm_label = preds[label]\n",
    "        if svm_label[i] == 1:\n",
    "            acc += 1\n",
    "    return acc/len(test_labels)\n",
    "\n",
    "def convert_predictions(preds):\n",
    "    tot_preds = list(range(len(preds[0])))\n",
    "    for i in range(len(preds)):\n",
    "        pred = preds[i]\n",
    "        for j in range(len(pred)):\n",
    "            if pred[j] == 1:\n",
    "                tot_preds[j] = i\n",
    "    return tot_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grab data\n",
    "# train_data, train_labels = get_train_data(5)\n",
    "# test_data, test_labels = get_test_data()\n",
    "# #slice labels\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "train_data = train_data[:1000]\n",
    "\n",
    "test_labels = test_labels[:200]\n",
    "test_data = test_data[:200]\n",
    "# #convert binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now predicting!\n",
      "time: 119.7089672088623\n",
      "0.205\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "preds = predict_svm((train_data,train_labels),(test_data,test_labels))\n",
    "print(\"time: \" + str(time.time()-start))\n",
    "\n",
    "acc = svm_acc(preds, test_labels)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  0  1  0  5  0  0  0  2  3]\n",
      " [ 0  3  2  1  1  0  1  1  4  1]\n",
      " [ 2  0  4  0  8  1  4  1  1  0]\n",
      " [ 2  0  4  0  4  4  3  1  1  0]\n",
      " [ 0  0  2  1  9  0  1  0  1  1]\n",
      " [ 1  1  3  1  8  0  1  2  1  0]\n",
      " [ 2  0  5  1 10  0  8  0  0  0]\n",
      " [ 4  2  1  0  5  1  1  4  0  0]\n",
      " [ 4  1  0  2  4  1  1  0 12  3]\n",
      " [ 6  0  0  1  4  0  0  1  7  2]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.30      0.45      0.36        20\n",
      "          1       0.43      0.21      0.29        14\n",
      "          2       0.18      0.19      0.19        21\n",
      "          3       0.00      0.00      0.00        19\n",
      "          4       0.16      0.60      0.25        15\n",
      "          5       0.00      0.00      0.00        18\n",
      "          6       0.40      0.31      0.35        26\n",
      "          7       0.40      0.22      0.29        18\n",
      "          8       0.41      0.43      0.42        28\n",
      "          9       0.20      0.10      0.13        21\n",
      "\n",
      "avg / total       0.26      0.26      0.24       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_preds = convert_predictions(preds)\n",
    "import random\n",
    "\n",
    "svm_preds = [random.randint(0,9) if p > 9 else p for p in svm_preds]\n",
    "\n",
    "conf = confusion_matrix(test_labels, pred_labels)\n",
    "clas_rep = classification_report(test_labels, pred_labels)\n",
    "print(conf)\n",
    "print(clas_rep)\n",
    "# f = open('report.txt', 'a')\n",
    "# f.write(\"\\nSTEP 4: \\n\")\n",
    "# f.write(str(conf))\n",
    "# f.write(\"\\n\\n\")\n",
    "# f.write(str(clas_rep))\n",
    "# f.write(\"\\n\\n\")\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(test_labels,svm_preds))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20197044 0.27722772 0.21393035 0.23115578 0.16923077]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = LinearSVC()\n",
    "scores = cross_val_score(clf, train_data[:1000], train_labels[:1000], cv=5)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  0  1  0  5  0  0  0  2  3]\n",
      " [ 0  3  2  1  1  0  1  1  4  1]\n",
      " [ 2  0  4  0  8  1  4  1  1  0]\n",
      " [ 2  0  4  0  4  4  3  1  1  0]\n",
      " [ 0  0  2  1  9  0  1  0  1  1]\n",
      " [ 1  1  3  1  8  0  1  2  1  0]\n",
      " [ 2  0  5  1 10  0  8  0  0  0]\n",
      " [ 4  2  1  0  5  1  1  4  0  0]\n",
      " [ 4  1  0  2  4  1  1  0 12  3]\n",
      " [ 6  0  0  1  4  0  0  1  7  2]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
